{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('check.csv', 'x') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import inspect\n",
    "import logging\n",
    "import typing\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from typing import Literal\n",
    "from threading import Lock\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from rich.logging import RichHandler\n",
    "\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "LOGLEVELS = Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"]\n",
    "\n",
    "_INIT_LOCK = Lock() # type: Lock\n",
    "_LOGGERS = [] # type: list\n",
    "\n",
    "def init_logger(\n",
    "    instance=None, module_name=None, class_name=None, object_name=None\n",
    ") -> logging.Logger:\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "    # gather variables\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    if instance is not None:\n",
    "        # get name of module_name without prefixed autopilot\n",
    "        # eg passed autopilot.hardware.gpio.Digital_In -> hardware.gpio\n",
    "        # filtering leading 'autopilot' from string\n",
    "\n",
    "        module_name = instance.__module__\n",
    "        if \"__main__\" in module_name:\n",
    "            # awkward workaround to get module name of __main__ run objects\n",
    "            mod_obj = inspect.getmodule(instance)\n",
    "            try:\n",
    "                mod_suffix  = inspect.getmodulename(inspect.getmodule(instance).__file__)\n",
    "                module_name = '.'.join([mod_obj.__package__, mod_suffix])\n",
    "            except AttributeError:\n",
    "                # when running interactively or from a plugin, __main__ does not have __file__\n",
    "                module_name = \"__main__\"\n",
    "\n",
    "        module_name = re.sub('^NeuRPi.', '', module_name)\n",
    "\n",
    "        class_name = instance.__class__.__name__\n",
    "\n",
    "        if hasattr(instance, 'id'):\n",
    "            object_name = str(instance.id)\n",
    "        elif hasattr(instance, 'name'):\n",
    "            object_name = str(instance.name)\n",
    "        else:\n",
    "            object_name = None\n",
    "\n",
    "\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # check if logger needs to be made, or exists already\n",
    "        # --------------------------------------------------\n",
    "    elif not any((module_name, class_name, object_name)):\n",
    "        raise ValueError('Need to either give an object to create a logger for, or one of module_name, class_name, or object_name')\n",
    "\n",
    "\n",
    "    # get name of logger to get\n",
    "    logger_name_pieces = [v for v in (module_name, class_name, object_name) if v is not None]\n",
    "    logger_name = '.'.join(logger_name_pieces)\n",
    "\n",
    "    # trim __ from logger names, linux don't like to make things like that\n",
    "    # re.sub(r\"^\\_\\_\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # if new logger must be made, make it, otherwise just return existing logger\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    # use a lock to prevent loggers from being double-created, just to be extra careful\n",
    "    with globals()['_INIT_LOCK']:\n",
    "\n",
    "        # check if something starting with module_name already exists in loggers\n",
    "        MAKE_NEW = False\n",
    "        if not any([test_logger == module_name for test_logger in globals()['_LOGGERS']]):\n",
    "            MAKE_NEW = True\n",
    "\n",
    "        if MAKE_NEW:\n",
    "            parent_logger = logging.getLogger(module_name)\n",
    "            loglevel = 'WARNING' #getattr(logging, prefs.get('LOGLEVEL'))\n",
    "            parent_logger.setLevel(loglevel)\n",
    "\n",
    "            # make formatter that includes name\n",
    "            log_formatter = logging.Formatter(\"[%(asctime)s] %(levelname)s [%(name)s]: %(message)s\")\n",
    "\n",
    "            ## file handler\n",
    "            # base filename is the module_name + '.log\n",
    "            base_filename = Path(module_name + '.log')\n",
    "\n",
    "            fh = _file_handler(base_filename)\n",
    "            fh.setLevel(loglevel)\n",
    "            fh.setFormatter(log_formatter)\n",
    "            parent_logger.addHandler(fh)\n",
    "\n",
    "            # rich logging handler for stdout\n",
    "            parent_logger.addHandler(_rich_handler())\n",
    "\n",
    "            # if our parent is the rootlogger, disable propagation to avoid printing to stdout\n",
    "            if isinstance(parent_logger.parent, logging.RootLogger):\n",
    "                parent_logger.propagate = False\n",
    "\n",
    "            ## log creation\n",
    "            globals()['_LOGGERS'].append(module_name)\n",
    "            parent_logger.debug(f'parent, module-level logger created: {module_name}')\n",
    "\n",
    "        logger = logging.getLogger(logger_name)\n",
    "        if logger_name not in globals()['_LOGGERS']:\n",
    "        # logger.addHandler(_rich_handler())\n",
    "            logger.debug(f\"Logger created: {logger_name}\")\n",
    "            globals()['_LOGGERS'].append(logger_name)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "def _rich_handler() -> RichHandler:\n",
    "    rich_handler = RichHandler(rich_tracebacks=True, markup=True)\n",
    "    rich_formatter = logging.Formatter(\n",
    "        \"[bold green]\\[%(name)s][/bold green] %(message)s\",\n",
    "        datefmt='[%y-%m-%dT%H:%M:%S]'\n",
    "    )\n",
    "    rich_handler.setFormatter(rich_formatter)\n",
    "    return rich_handler\n",
    "\n",
    "def _file_handler(base_filename: Path) -> RotatingFileHandler:\n",
    "    # if directory doesn't exist, try to make it\n",
    "    if not base_filename.parent.exists():\n",
    "        base_filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fh = RotatingFileHandler(\n",
    "        str(base_filename),\n",
    "        mode='a',\n",
    "        maxBytes=int(20*(2**20) ),\n",
    "        backupCount=int(4)\n",
    "        )\n",
    "    return fh\n",
    "\n",
    "from NeuRPi.hardware.arduino import Arduino\n",
    "a = Arduino()\n",
    "b = init_logger(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'H5F_Group' object has no attribute '_init_logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSubjectStructure\u001b[39;00m():\n\u001b[0;32m      2\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    Structure of the :class:`.Subject` class's hdf5 file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     info \u001b[39m=\u001b[39m H5F_Group(path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/info\u001b[39m\u001b[39m\"\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSubject Biographical Information\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [52], line 6\u001b[0m, in \u001b[0;36mSubjectStructure\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSubjectStructure\u001b[39;00m():\n\u001b[0;32m      2\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    Structure of the :class:`.Subject` class's hdf5 file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     info \u001b[39m=\u001b[39m H5F_Group(path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/info\u001b[39;49m\u001b[39m\"\u001b[39;49m, title\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSubject Biographical Information\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m     data \u001b[39m=\u001b[39m H5F_Group(\n\u001b[0;32m      8\u001b[0m         path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/data\u001b[39m\u001b[39m\"\u001b[39m, filters\u001b[39m=\u001b[39mtables\u001b[39m.\u001b[39mFilters(complevel\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, complib\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mblosc:lz4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     )\n\u001b[0;32m     10\u001b[0m     protocol \u001b[39m=\u001b[39m H5F_Group(\n\u001b[0;32m     11\u001b[0m         path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/protocol\u001b[39m\u001b[39m\"\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMetadata for the currently assigned protocol\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m     )\n",
      "Cell \u001b[1;32mIn [50], line 13\u001b[0m, in \u001b[0;36mH5F_Node.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata):\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_logger()\n\u001b[0;32m     14\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'H5F_Group' object has no attribute '_init_logger'"
     ]
    }
   ],
   "source": [
    "class SubjectStructure():\n",
    "    \"\"\"\n",
    "    Structure of the :class:`.Subject` class's hdf5 file\n",
    "    \"\"\"\n",
    "\n",
    "    info = H5F_Group(path=\"/info\", title=\"Subject Biographical Information\")\n",
    "    data = H5F_Group(\n",
    "        path=\"/data\", filters=tables.Filters(complevel=6, complib=\"blosc:lz4\")\n",
    "    )\n",
    "    protocol = H5F_Group(\n",
    "        path=\"/protocol\", title=\"Metadata for the currently assigned protocol\"\n",
    "    )\n",
    "    history = H5F_Group(\n",
    "        path=\"/data/task_name/phase/\",\n",
    "        children=[\n",
    "            H5F_Group(path=\"/history/past_protocols\", title=\"Past Protocol Files\"),\n",
    "            _Hash_Table(path=\"/history/hashes\", title=\"Git commit hash history\"),\n",
    "            _History_Table(path=\"/history/history\", title=\"Change History\"),\n",
    "            _Weight_Table(path=\"/history/weights\", title=\"Subject Weights\"),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5F_Group(H5F_Node):\n",
    "    \"\"\"\n",
    "    Description of a pytables group and its location\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    children: Optional[List[Union[H5F_Node, 'H5F_Group']]] = None\n",
    "        \n",
    "    def make(self, h5f:tables.file.File):\n",
    "        \"\"\"\n",
    "        Make the group, if it doesn't already exist.\n",
    "\n",
    "        If it exists, do nothing\n",
    "\n",
    "        Args:\n",
    "            h5f (:class:`tables.file.File`): The file to create the table in\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            node = h5f.get_node(self.path)\n",
    "            # if no exception, already exists\n",
    "            if not isinstance(node, tables.group.Group):\n",
    "                raise ValueError(f'{self.path} already exists, but it isnt a group! instead its a {type(node)}')\n",
    "        except tables.exceptions.NoSuchNodeError:\n",
    "            group = h5f.create_group(self.parent, self.name,\n",
    "                             title=self.title, createparents=True,\n",
    "                             filters=self.filters)\n",
    "            self._logger.debug(f\"Made group {'/'.join([self.parent, self.name])}\")\n",
    "            if self.attrs is not None:\n",
    "                group._v_attrs.update(self.attrs)\n",
    "\n",
    "        if self.children is not None:\n",
    "            for c in self.children:\n",
    "                c.make(h5f)\n",
    "        h5f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from abc import abstractmethod\n",
    "\n",
    "class H5F_Node(Node):\n",
    "    \"\"\"\n",
    "    Base class for H5F Nodes\n",
    "    \"\"\"\n",
    "    path:str\n",
    "    title:Optional[str]=''\n",
    "    filters:Optional[tables.filters.Filters]=None\n",
    "    attrs:Optional[dict]=None\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        self._init_logger()\n",
    "        super().__init__(**data)\n",
    "\n",
    "    @property\n",
    "    def parent(self) -> str:\n",
    "        \"\"\"\n",
    "        The parent node under which this node hangs.\n",
    "\n",
    "        Eg. if ``self.path`` is ``/this/is/my/path``, then\n",
    "        parent will be ``/this/is/my``\n",
    "\n",
    "        Returns:\n",
    "            str\n",
    "        \"\"\"\n",
    "        return '/'.join(self.path.split('/')[:-1])\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        \"\"\"\n",
    "        Our path without :attr:`.parent`\n",
    "\n",
    "        Returns:\n",
    "            str\n",
    "        \"\"\"\n",
    "        return self.path.split('/')[-1]\n",
    "\n",
    "    @abstractmethod\n",
    "    def make(self, h5f:tables.file.File):\n",
    "        \"\"\"\n",
    "        Abstract method to make whatever this node is\n",
    "        \"\"\"\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBase Python types that should be suppported by every interface\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Base classes for data models -- the ``Data`` class itself.\n",
    "\"\"\"\n",
    "import typing\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import tables\n",
    "\n",
    "\n",
    "class Data():\n",
    "    \"\"\"\n",
    "    The top-level container for Data.\n",
    "\n",
    "    Subtypes will define more specific formats and uses of data, but this is the most general\n",
    "    form used to represent the type and meaning of data.\n",
    "\n",
    "    The Data class is not intended to contain individual fields, but collections of data that are collected\n",
    "    as a unit, whether that be a video frame along with its timestamp and encoding, or a single trial of behavioral data.\n",
    "\n",
    "    This class is also generally not intended to be used for the literal transport of data when performance is\n",
    "    necessary: this class by default does type validation on instantiation that takes time (see the `construct <https://pydantic-docs.helpmanual.io/usage/models/#creating-models-without-validation>`_\n",
    "    method for validation-less creation). It is usually more to specify the type, grouping, and annotation for\n",
    "    a given unit of data -- though users should feel free to dump their data in a :class:`.Data` object if\n",
    "    it is not particularly performance sensitive.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class Table(Data):\n",
    "    \"\"\"\n",
    "    Tabular data: each field will have multiple values -- in particular an equal number across fields.\n",
    "\n",
    "    Used for trialwise data, and can be used to create pytables descriptions.\n",
    "\n",
    "    .. todo::\n",
    "\n",
    "        To make this usable as a live container of data, the fields need to be declared as Lists (eg. instead of just\n",
    "        declaring something an ``int``, it must be specified as a ``List[int]`` to pass validation. We should expand this\n",
    "        model to relax that constraint and effectively treat every field as containing a list of values.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def to_pytables_description(cls) -> typing.Type[tables.IsDescription]:\n",
    "        \"\"\"\n",
    "        Convert the fields of this table to a pytables description.\n",
    "\n",
    "        See :func:`~.interfaces.tables.model_to_description`\n",
    "        \"\"\"\n",
    "        from autopilot.data.interfaces.tables import model_to_description\n",
    "\n",
    "        return model_to_description(cls)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pytables_description(\n",
    "        cls, description: typing.Type[tables.IsDescription]\n",
    "    ) -> \"Table\":\n",
    "        \"\"\"\n",
    "        Create an instance of a table from a pytables description\n",
    "\n",
    "        See :func:`~.interfaces.tables.description_to_model`\n",
    "\n",
    "        Args:\n",
    "            description (:class:`tables.IsDescription`): A Pytables description\n",
    "        \"\"\"\n",
    "        from autopilot.data.interfaces.tables import description_to_model\n",
    "\n",
    "        return description_to_model(description, cls)\n",
    "\n",
    "    def to_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a dataframe from the lists of fields\n",
    "\n",
    "        Returns:\n",
    "            :class:`pandas.DataFrame`\n",
    "        \"\"\"\n",
    "        return pd.DataFrame(self.dict())\n",
    "\n",
    "\n",
    "class Attributes(Data):\n",
    "    \"\"\"\n",
    "    A set of attributes that is intended to have a single representation per usage:\n",
    "    eg. a subject has a single set of biographical information.\n",
    "\n",
    "    Useful to specify a particular type of storage that doesn't need to include variable\n",
    "    numbers of each field (eg. the tables interface stores attribute objects as metadata on a node, rather than as a table).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class Schema():\n",
    "    \"\"\"\n",
    "    A special type of type intended to be a representation of an\n",
    "    abstract structure/schema of data, rather than a live container of\n",
    "    data objects themselves. This class is used for constructing data containers,\n",
    "    translating between formats, etc. rather than momentary data handling\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class Node():\n",
    "    \"\"\"\n",
    "    Abstract representation of a Node in a treelike or linked data structure.\n",
    "    This should be extended by interfaces when relevant and needed to implement\n",
    "    an abstract representation of their structure.\n",
    "\n",
    "    This class purposely lacks structure like a path or parents pending further\n",
    "    usage in interfaces to see what would be the best means of implementing them.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class Group():\n",
    "    \"\"\"\n",
    "    A generic representation of a \"Group\" if present in a given interface.\n",
    "    Useful for when, for example in a given container format you want to\n",
    "    make an empty group that will be filled later, or one that has to be\n",
    "    present for syntactic correctness.\n",
    "\n",
    "    A children attribute is present because it is definitive of groups, but\n",
    "    should be overridden by interfaces that use it.\n",
    "    \"\"\"\n",
    "\n",
    "    children: Optional[List[Node]] = None\n",
    "\n",
    "\n",
    "BASE_TYPES = (bool, int, float, str, bytes, datetime)\n",
    "\"\"\"\n",
    "Base Python types that should be suppported by every interface\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64fb13e557eb23a1af02c748ef9b191ec10c8867fc28ad6676f3671f65dfe8ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
